---
title: "Data607_Project3"
author: "ritwaru"
date: "October 16, 2018"
output: html_document
---
```{r, include=FALSE}
# load libraries
require(rvest)
require(stringr)
require(dplyr)
require(wordcloud)
require(dplyr)
require(RColorBrewer)
require(ggplot2)
```

```{r}

# Indeed advance search was used to get a link for 50 job postings  per page  that has to do with Data Science.

job_posting_site <- 'https://www.indeed.com'

#job_listings_url <- "https://www.indeed.com/jobs?q=Advanced%20Search&l&ts=1539732040434&rs=1&fromage=last"
job_listings_url <- "https://www.indeed.com/jobs?q=data+scientist&l=new+york&explvl=senior_level&limit=50"

# Some basic skill sets that are ussually found in Data Science job postings.
Skills <- c("AWS", "Python", "AI", "SQL", "R", "SAS", "Tableau", "AZURE", "SparkML", "Shiny", "Spark", "Hadoop", "Machine Learning", "Probability", "Statistics")
#Skills <- c("AWS", "Python")

# Webscrape the result page data using the 'read_html' function from rvest
indeed_ds_job_listings <- read_html(job_listings_url)


# Function to gather the links for the job posts.
getjoblinks <- function(jburls){
#Indeed seems to stores it's joblising URLs using different css formats. We will attempt to get these URLs using two different html_nodes search options.
  
# Gather job posting URLs under the <h2> tags with <a> tag 
  try(
    job_posting_urls1 <- jburls %>%
      html_nodes("h2 a") %>%
      html_attr('href')
  )
    


# Gather job posting URLs that are in <a> tags with 'id' that starts with 'sja'
  try(
    job_posting_urls2 <- jburls %>%
      html_nodes(xpath='//*[starts-with(@id, "sja")]') %>%
      html_attr('href')
  )
  
#job_posting_urls2
a <- data.frame(job_posting_urls1)
names(a) <- ("Job_Listings_URL")
b <- data.frame(job_posting_urls2)
names(b) <- ("Job_Listings_URL")
c <- rbind(a, b)

}

job_posting_urls <- getjoblinks(indeed_ds_job_listings)

# Function to gather the links for the additional result pages.

getresultlinks <- function(jrpurls){
  try(
    job_restult_urls <- jrpurls %>%
    html_nodes(xpath = '//div[contains(@class,"pagination")]//a') %>%
    html_attr('href')
  )
  
}

# Function to search for specific key words in a webpage.
job_posting_skills = data.frame()

getkeywords <- function(urldf){
  
  for(i in 1:nrow(urldf)){
    job_post_link <- paste0(job_posting_site,indeed_job_postings_URLs$Job_Listings_URL[i])
    
    try(
      job_post_data <- read_html(job_post_link)
    )
    
    for(i1 in 1:length(Skills)){
      job_posting_skills1 <- str_match(job_post_data, Skills[i1])
      job_posting_skills2 <- data.frame(job_posting_skills1)
      job_posting_skills <- rbind(job_posting_skills2, job_posting_skills)
      
    }
  }
  na.omit(job_posting_skills)

}


#Retrieve the links for the additional result pages
indeed_rs_ds_job_listings1 <- getresultlinks(indeed_ds_job_listings)

# Get the job posting URLs from the additional result pages
i <- length(indeed_rs_ds_job_listings1) - 1

job_resultpages_urls = data.frame()
for (l in 1:i) {
  indeed_rs_ds_job_listings2 <- read_html(paste0(job_posting_site,indeed_rs_ds_job_listings1[l]))
  indeed_rs_ds_job_listings3 <- getjoblinks(indeed_rs_ds_job_listings2)
  indeed_rs_ds_job_listings4 <- data.frame(indeed_rs_ds_job_listings3)
  job_resultpages_urls <- rbind(indeed_rs_ds_job_listings4, job_resultpages_urls)

}
# Change Column name to match the column name of the data frame holding the job posting URLs of 'page 1'
names(job_resultpages_urls) <- ("Job_Listings_URL")

# Merge both dataframes containing the job posting URLs 
indeed_job_postings_URLs <- rbind(job_posting_urls, job_resultpages_urls)

job_links_count <- nrow(indeed_job_postings_URLs)

# Skill that we found based on our keywords search are stored in a dataframe
job_listings_keywords <- getkeywords(indeed_job_postings_URLs)
row.names(job_listings_keywords) <- NULL
names(job_listings_keywords) <- ("Data_Scientist_Skills")

# Count Skills 
job_listings_keyword_count <- job_listings_keywords %>%
  group_by(Data_Scientist_Skills) %>% count(Data_Scientist_Skills)
#job_listings_keyword_count
p<-ggplot(job_listings_keyword_count, aes(x=Data_Scientist_Skills, y=n, fill=Data_Scientist_Skills)) +
  geom_bar(stat="identity")+theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ggtitle("Data Scientist Skills")
p


# Build a word cloud
pal2 <- brewer.pal(8,"Dark2")
job_listings_keywords1 <- count(job_listings_keywords, Data_Scientist_Skills)
wordcloud(words = job_listings_keywords1$Data_Scientist_Skills, freq = job_listings_keywords1$n, min.freq = 1, colors = pal2)
```

```{r tech skills output, echo=FALSE}
colnames(job_listings_keywords) <- c("Tech.Skill")
write.csv(job_listings_keywords, file = "TechSkills.csv") 

colnames(job_listings_keyword_count) <- c("Tech.Skill", "Count")
write.csv(job_listings_keyword_count, file = "TechSkillsSummary.csv")  
```
